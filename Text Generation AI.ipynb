{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11cc78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import heapq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d15f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv(\"news.csv\")\n",
    "text = list(text_df.text.values)\n",
    "joined_text = \" \".join(text)\n",
    "\n",
    "with open(\"joined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1436ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_text = joined_text[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4f2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83fb22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token: index for index, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eff7c24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1325/1325 [==============================] - 1163s 872ms/step - loss: 7.0565 - accuracy: 0.0689\n",
      "Epoch 2/10\n",
      "1325/1325 [==============================] - 1140s 861ms/step - loss: 6.6369 - accuracy: 0.1048\n",
      "Epoch 3/10\n",
      "1325/1325 [==============================] - 1058s 799ms/step - loss: 6.4412 - accuracy: 0.1203\n",
      "Epoch 4/10\n",
      "1325/1325 [==============================] - 1058s 798ms/step - loss: 6.2702 - accuracy: 0.1330\n",
      "Epoch 5/10\n",
      "1325/1325 [==============================] - 1067s 805ms/step - loss: 6.1118 - accuracy: 0.1456\n",
      "Epoch 6/10\n",
      "1325/1325 [==============================] - 1055s 796ms/step - loss: 5.9522 - accuracy: 0.1572\n",
      "Epoch 7/10\n",
      "1325/1325 [==============================] - 1054s 795ms/step - loss: 5.8061 - accuracy: 0.1702\n",
      "Epoch 8/10\n",
      "1325/1325 [==============================] - 1061s 801ms/step - loss: 5.6527 - accuracy: 0.1835\n",
      "Epoch 9/10\n",
      "1325/1325 [==============================] - 1075s 812ms/step - loss: 5.5227 - accuracy: 0.1949\n",
      "Epoch 10/10\n",
      "1325/1325 [==============================] - 1158s 874ms/step - loss: 5.4019 - accuracy: 0.2056\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "n_words = 10\n",
    "input_words = []\n",
    "next_word = []\n",
    "\n",
    "for i in range(len(tokens) - n_words):\n",
    "    input_words.append(tokens[i:i + n_words])\n",
    "    next_word.append(tokens[i + n_words])\n",
    "\n",
    "n_samples = len(input_words)\n",
    "n_unique_tokens = len(unique_tokens)\n",
    "\n",
    "X = lil_matrix((n_samples, n_words * n_unique_tokens), dtype=bool)\n",
    "y = lil_matrix((n_samples, n_unique_tokens), dtype=bool)\n",
    "\n",
    "for i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        if word in unique_token_index:\n",
    "            token_index = unique_token_index[word]\n",
    "            X[i, j * n_unique_tokens + token_index] = 1\n",
    "\n",
    "    if next_word[i] in unique_token_index:\n",
    "        next_token_index = unique_token_index[next_word[i]]\n",
    "        y[i, next_token_index] = 1\n",
    "\n",
    "X = X.tocsr()\n",
    "y = y.tocsr()\n",
    "\n",
    "def data_generator():\n",
    "    while True:\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            X_batch = X[i:i + batch_size].toarray().reshape((-1, n_words, n_unique_tokens))\n",
    "            y_batch = y[i:i + batch_size].toarray()\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, n_unique_tokens), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(n_unique_tokens))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "batch_size = 128\n",
    "steps_per_epoch = n_samples // batch_size\n",
    "\n",
    "history = model.fit(data_generator(), steps_per_epoch=steps_per_epoch, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cc8adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"text_gen_model2.h5\")\n",
    "with open(\"history2.p\", \"wb\") as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4fa0e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"text_gen_model2.h5\")\n",
    "history = pickle.load(open(\"history2.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "365b0bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    X = np.zeros((1, n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        X[0, i, unique_token_index[word]] = 1\n",
    "        \n",
    "    predictions = model.predict(X)[0]\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81e5536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    }
   ],
   "source": [
    "possible = predict_next_word(\"I will have to look into this thing because I\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8d48a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could\n",
      "will\n",
      "would\n",
      "can\n",
      "had\n"
     ]
    }
   ],
   "source": [
    "for idx in possible:\n",
    "    print(unique_tokens[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f2f3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text, n_words, creativity=3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(n_words):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd92d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I will have to look into this thing because I would see we need your wife to keep hillary national orders study sharpton solution over women obamacare food biden give 100 off north points the order should look be from obamacare obama has taken me more weeks between us white states on a major re man on a white court based by the current federal crisis of undocumented leader vote executive carney pledges on bad sharpton obama s memoir in congress finds white site obama to search away into putin 100 away in been un back and whether america were women based to keep his executive border america could help'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"I will have to look into this thing because I\", 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e77066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The president of the United States announced yesterday that he got a stunning idea we d see you need the obama speech i is like what it means in to talk that he found more putin than with people study white man administration and executive qaeda declaring putin to raise our name which gets over putin s executive gov joe calls off ukraine the world media broke off isis un among study of economic employees for violent gov obamacare phone executive hebdo class act paul williamson obama said putin and executive john williamson john carney obamacare s dogs of federal leader order putin to search on back obamacare with economic'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"The president of the United States announced yesterday that he\", 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e29fcbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "whether\n",
      "me\n",
      "obama\n",
      "us\n",
      "your\n"
     ]
    }
   ],
   "source": [
    "for idx in predict_next_word(\"The president will most likely not be there to help\", 5):\n",
    "    print(unique_tokens[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
